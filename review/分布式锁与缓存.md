### 缓存的使用与分布式锁

缓存穿透，缓存击穿，缓存雪崩

缓存穿透是指缓存和数据库中都没有要查询的数据，那么这个查询一定会穿过缓存不断的查库，一般这种情况是有人恶意的发起请求来攻击数据库，造成数据库压力骤增甚至宕机，解决办法除了接口校验非法数据外，还有缓存null值到redis中以及布隆过滤器的方式

缓存击穿是大并发查询一条数据，但这个数据突然过期了，或者压根就没进缓存，就是一个突然出现的热key，那么京东零售开源的hotkey可以使用，毫秒级别探测热点key，然后迅速将热点key加入缓存，还有一种方式就是分布式锁，出现查不到的情况后，只允许放进去一个线程去查库，其他线程阻塞，阻塞完成进入代码块后，还需要再一次查询缓存，如果缓存中有那么就走缓存，如果缓存没有就走数据库，其实单纯使用本地锁也足以应对，大不了每个服务放进来一个线程去查库，也能大大降低数据库的压力

缓存雪崩是大面积key同时失效，请求转发到DB，DB崩了

对于缓存雪崩，先说一下事前的预防：

1.缓存数据过期时间尽量分散，防止同一时间大量key失效

2.将热点数据分布在不同的缓存数据库中

3.设置超级热点的数据永不过期（一致性方面采用延时双删），超级热点数据一般比如秒杀商品等，其实上架后也就不需要改变了，对于数据一致性根据情况而定，如果需要强一致，那么就延时双删，不着急的话可以消息队列，中间件订阅mysqlbinlog来通知redis删除数据等

这是事前预防，还是事中的处理：

出现雪崩，首先可以降级，限流，熔断，保护数据库，不让数据库崩掉，以至于整个服务不可用

以及除了使用分布式缓存，还应该有本地缓存做后备

然后立马去将数据加入到缓存中，在慢慢恢复熔断

另外这里再说一下本地缓存的弊端，也就是本地使用hashmap和用redis的区别是什么，首先本地缓存宕机以后就没了，没有办法持久化，其次数据一致性问题，数据更新时只是把自己服务内存的数据改了，造成数据不一致

### redis做分布式锁

单机情况下redis做分布式锁的演进：

1.首先可以使用setnx命令配合delete命令进行加锁解锁，key不能变，value可变，那么占完坑以后如果服务器宕机，那么即使delete删锁代码写在finally代码块中，都不会执行删锁代码，最终造成这个锁无法被解锁

2.那么解决办法就是加上锁的过期时间，即使没有删锁，过期了也会自动删除，但是如果加上过期时间的代码和加锁代码不是原子性的，那么加完锁没来得及设置过期时间，那么也会无法解锁，所以加锁和设置过期时间必须是原子操作

3.现在就不怕锁没法被删了，出现了新的问题，如果业务执行时间超长，长过了设置的过期时间，那么在业务执行的过程中，锁就自动消亡了，这时其他线程又拿到了锁，而这个业务执行完以后又要删锁，相当于你把其他线程的锁删了，这种解决办法就是设置一个uuid，让每个线程只能删除自己的锁，也就是setifabsent中的value值，应该设置成每一个线程自己随机出来的uuid，删锁的时候需要比对uuid是否跟自己刚开始生成的uuid相同，如果相同才执行删锁，如果不同，证明自己的锁已经被过期时间自动删除，自己无需再次删锁

4.但是这块还有一个问题，假设锁的过期时间为10s，业务执行了9.5s，向redis发送get用了0.3s，返回用0.3s，在redis向我返回uuid的时候，这个uuid确实是我自己的，但是锁在第10s过期了，进来一个新的uuid的新设置的锁，但是返回到你手里你一对比，又发现确实是我的uuid，那么执行删锁，相当于又把别人的锁删了，所以这里最终的是查锁比对，以及比对成功以后删锁这一系列操作都是一个原子性的操作

5.那么最终的方案就出来了，setIfAbsent，带上uuid，带上过期时间，解锁的时候lua脚本查询uuid并进行比对，比对成功再删锁

这就是单机版的redis做原生命令做分布式锁的演进过程

对于这种一套步骤，其实使用redisson更方便

另外上面的这种步骤其实并没有解决业务超长状态下锁提前删了的问题，虽然加了uuid，并且原子删除，可以避免锁别人的情况，但是你最终还是让别人在你执行的过程中进来了，我们应该希望这是串行化执行的

redisson最优秀的地方在于提供了看门狗机制，如果不设置默认超时时间，那么锁的过期时间是30s，并且如果业务执行时间超长，那么会在三分之一看门狗时间后进行一次续期，也就是如果锁的时间剩了20s了，那么会自动续期到30s，如果业务执行完毕了，执行unlock方法解锁，如果宕机，那么等过期时间就行，也会最终解锁

并且这个redisson的lock，并不需要uuid，只需要传一个lockName就行了，因为它的RLock对象完全符合java的lock规范，也就是说只有拥有锁的线程才能解锁